
<!-- TOC -->

    - [0.1. 特征分解](#01-特征分解)
    - [0.2. 奇异值分解： singular value decomposition](#02-奇异值分解-singular-value-decomposition)
    - [0.3. 行列式](#03-行列式)
    - [0.4. 主成分分析   principal components analysis, PCA](#04-主成分分析---principal-components-analysis-pca)
        - [0.4.1. 方差](#041-方差)
        - [0.4.2. 协方差](#042-协方差)
            - [0.4.2.1. 协方差的一些属性](#0421-协方差的一些属性)
    - [0.5. 矩阵转置](#05-矩阵转置)
    - [0.6. 矩阵乘法](#06-矩阵乘法)
        - [0.6.1. 协方差矩阵 covariance matrix](#061-协方差矩阵-covariance-matrix)
- [疑惑点](#疑惑点)

<!-- /TOC -->


## 0.1. 特征分解
方阵$A$的特征向量是指$A$相乘后相当于对该向量进行缩放的非零向量$v$   

$$\textbf{Av} = \lambda \textbf{v}$$
标量$\lambda$被称为特征向量对应的特征值（eigenvalue）。
由于任何缩放后的sv都是A的特征向量，因此更关注单位特征向量。


正交矩阵：指行向量和列向量时分别标准正交的方阵。
$A A^T = A^T A = I$  

矩阵$A$的特征分解
将特征向量链接成一个矩阵$V$，将特征值连接成一个向量$\lambda$， $A$的特征分解可以记作：

$$A = V diag( \lambda ) V^{-1}$$

每个实对称矩阵可以分解成实特征向量和实特征值：

$$A = Q \Lambda Q^{-T}$$

其中 $Q$ 是$A$的特征向量组成的正交矩阵，$\Lambda$是对角矩阵。特征值$\Lambda_{i,i}$ 对应的特征向量是矩阵$Q$的第$i$列，记作 $Q_{:,i}$ 


矩阵奇异：当且仅当含有零特征值。


## 0.2. 奇异值分解： singular value decomposition

每个实数矩阵都有一个奇异值分解，但不一定都有特征分解。
非方阵没有特征分解。

奇异值分解：

$$A = U D V^{T}$$
A-> m*n
U-> m*m
D-> m*n
V-> n*n
U和V都是正交矩阵。

计算矩阵的违逆 Moore-Penrose pseudoinverse

$$A^+ = V D^+ U^T$$

其中，矩阵 U， D 和 V 是矩阵 A奇异值分解后得到的矩阵。对角矩阵 D 的伪逆
D+ 是其非零元素取倒数之后再转置得到的。


迹运算（trace），取的是矩阵对角元素的和：

$$Tr(A) = \sum_i A_{i,i}$$

多个矩阵相乘，元素循环挪动，其迹是相同的


## 0.3. 行列式

## 0.4. 主成分分析   principal components analysis, PCA
$Y=PX$ 用基向量乘原始向量。进行数据降维，但是数据原有的特征损失不大。


### 0.4.1. 方差

https://en.wikipedia.org/wiki/Variance

方差定义及推导过程

$$Var(X) = E[(X- E[X] )^2]   \\
         = E[ X^2 - 2XE[X] + (E[X])^2 ] \\
         = E[X^2] - 2E[X]E[X] + (E[X])^2    \\
         = E[X^2] - (E[X])^2
$$

方差和协方差的关系

$$Var(X) = Cov(X,X)$$

### 0.4.2. 协方差

https://en.wikipedia.org/wiki/Covariance

协方差定义及推导过程

$$Cov(X,Y) = E((X-E[X])(Y-E[Y]))  \\
            = E( XY - XE[Y] - YE[X] + E[X]E[Y] )    \\
            = E(XY) - 2E[X]E[Y] + E[X]E[Y]  \\
            = E(XY) - E[X]E[Y]
$$

#### 0.4.2.1. 协方差的一些属性
-   cov(X,X) = var(X)
-   cov(X,Y) = cov(Y,X)
-   cov(aX,bY) = ab cov(X,Y)


## 0.5. 矩阵转置
https://en.wikipedia.org/wiki/Transpose

模仿matlab, $A' = A^T$
大写为矩阵，小写为标量.
-   (A')' = A
-   (A + B)' = A' + B'
-   (AB)' = B'A'
-   (cA)' = cA'
-   det(A') = det(A)

## 0.6. 矩阵乘法
https://en.wikipedia.org/wiki/Matrix_multiplication

$$c_{ij} = \sum _{k=1} ^{m} {a_{ik} b_{k,j}}$$

模仿matlab，点乘为 $A .* B$ 叉乘为 $A*B$

矩阵乘法的一些性质

-   一般地  AB != BA
-   AB = BA 成立的条件：都为方阵，其中一个为单位阵
-   A(B+C) = AB + BC
-   (B+C)D = BD + CD
-   cA = Ac
-   c(AB) = (cA)B = A(Bc)
-   (AB)C = A(BC)


### 0.6.1. 协方差矩阵 covariance matrix
对于单一列向量X，协方差矩阵的第(i,j)项的定义如下：

$$\sum_{ij} = cov(X_i, X_j))    \\
= E[(X_i - E[X_i])(X_j - E[X_j])]   \\
= E[X_i X_j] - (E[X_i] E[X_j])
$$

对于整体的协方差矩阵，其简洁定义如下

$$\sum = E [(E-E[X])(E-E[X])']$$

将单维向量向高维推广：

$$var(X) = E[(X-E[X])(X-E[X])'] $$

$$cov(X,Y) = E[(X-E[X]) (Y-E[Y])']$$

# 疑惑点

对称矩阵： 
$A=A^T$


方阵可以使用特征值分解，非方阵需要使用奇异值分解


